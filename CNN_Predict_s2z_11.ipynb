{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Architecture for Predicting s2z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "import random\n",
    "import h5py as h5\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 6000, 1, 64)\n",
      "(?, 1200, 1, 128)\n",
      "(?, 240, 1, 256)\n",
      "(?, 48, 1, 256)\n",
      "(?, 12, 1, 256)\n"
     ]
    }
   ],
   "source": [
    "#Placeholders\n",
    "x = tf.placeholder(tf.float32, shape = [None, 30000])\n",
    "y = tf.placeholder(tf.float32, shape = [None, 3])\n",
    "\n",
    "#Reshape input\n",
    "inp = tf.reshape(x, [-1, 30000, 1, 1])\n",
    "\n",
    "#Convolutional layer 1,2\n",
    "w_conv1 = weight('w_conv1', [80, 1, 1, 64])\n",
    "b_conv1 = bias('b_conv1', [64])\n",
    "conv1 = tf.nn.relu(conv(inp, w_conv1) + b_conv1)\n",
    "\n",
    "w_conv2 = weight('w_conv2', [20, 1, 64, 64])\n",
    "b_conv2 = bias('b_conv2', [64])\n",
    "conv2 = tf.nn.relu(conv(conv1, w_conv2) + b_conv2)\n",
    "\n",
    "#Max pool 1\n",
    "conv2 = maxPool(conv2, 5)\n",
    "print(conv2.shape)\n",
    "\n",
    "#Convolutional layer 3,4\n",
    "w_conv3 = weight('w_conv3', [5, 1, 64, 128])\n",
    "b_conv3 = bias('b_conv3', [128])\n",
    "conv3 = tf.nn.relu(conv(conv2, w_conv3) + b_conv3)\n",
    "\n",
    "w_conv4 = weight('w_conv4', [5, 1, 128, 128])\n",
    "b_conv4 = bias('b_conv4', [128])\n",
    "conv4 = tf.nn.relu(conv(conv3, w_conv4) + b_conv4)\n",
    "\n",
    "#Max pool 2\n",
    "conv4 = maxPool(conv4, 5)\n",
    "print(conv4.shape)\n",
    "\n",
    "#Convolutional layer 5\n",
    "w_conv5 = weight('w_conv5', [5, 1, 128, 256])\n",
    "b_conv5 = bias('b_conv5', [256])\n",
    "conv5 = tf.nn.relu(conv(conv4, w_conv5) + b_conv5)\n",
    "\n",
    "#Convolutional layer 6\n",
    "w_conv6 = weight('w_conv6', [5, 1, 256, 256])\n",
    "b_conv6 = bias('b_conv6', [256])\n",
    "conv6 = tf.nn.relu(conv(conv5, w_conv6) + b_conv6)\n",
    "\n",
    "#Max pool 3\n",
    "conv6 = maxPool(conv6, 5)\n",
    "print(conv6.shape)\n",
    "\n",
    "#Convolutional layer 7\n",
    "w_conv7 = weight('w_conv7', [5, 1, 256, 256])\n",
    "b_conv7 = bias('b_conv7', [256])\n",
    "conv7 = tf.nn.relu(conv(conv6, w_conv7) + b_conv7)\n",
    "\n",
    "#Convolutional layer 8\n",
    "w_conv8 = weight('w_conv8', [5, 1, 256, 256])\n",
    "b_conv8 = bias('b_conv8', [256])\n",
    "conv8 = tf.nn.relu(conv(conv7, w_conv8) + b_conv8)\n",
    "\n",
    "#Max pool 4\n",
    "conv8 = maxPool(conv8, 5)\n",
    "print(conv8.shape)\n",
    "\n",
    "#Convolution layer 9\n",
    "w_conv9 = weight('w_conv9', [5, 1, 256, 256])\n",
    "b_conv9 = bias('b_conv9', [256])\n",
    "conv9 = tf.nn.relu(conv(conv8, w_conv9) + b_conv9)\n",
    "\n",
    "#Max pool 5\n",
    "conv9 = maxPool(conv9, 4)\n",
    "print(conv9.shape)\n",
    "\n",
    "#Flatten\n",
    "flat = tf.reshape(conv9, [-1, 12 * 256])\n",
    "\n",
    "#Fully connected layer\n",
    "w_fc = weight('w_fc', [12 * 256, 20])\n",
    "b_fc = bias('b_fc', [20])\n",
    "fc = tf.nn.relu(tf.matmul(flat, w_fc) + b_fc)\n",
    "#fc = tf.nn.dropout(fc, .9)\n",
    "\n",
    "\n",
    "#Output layer\n",
    "w_fc1 = weight('w_fc1', [20, 3])\n",
    "b_fc1 = bias('b_fc1', [3])\n",
    "prediction = (tf.matmul(fc, w_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lr, batch_size, threshold, epochs):\n",
    "    \n",
    "    print(\"\\n######################################\")\n",
    "    print(\"Learning rate: \" + str(lr) + \" Batch size: \" + str(batch_size))\n",
    "    print(\"######################################\\n\")\n",
    "\n",
    "    cost = (tf.losses.mean_squared_error(prediction, y))\n",
    "\n",
    "    re_q = tf.divide(tf.abs(tf.subtract(prediction[:,0], y[:,0])), y[:,0]) * 100  #Relative error\n",
    "    re_s1z = tf.divide(tf.abs(tf.subtract(prediction[:,1], y[:,1])), y[:,1]) * 100  #Relative error\n",
    "    re_s2z = tf.divide(tf.abs(tf.subtract(prediction[:,2], y[:,2])), (y[:,2])) * 100  #Relative error\n",
    "\n",
    "    q = tf.reduce_mean(re_q)\n",
    "    s1z = tf.reduce_mean(re_s1z)\n",
    "    s2z = tf.reduce_mean(re_s2z)\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(lr).minimize(cost)\n",
    "\n",
    "    # config = tf.ConfigProto(device_count = {'GPU': 0}) #Use CPU instead of GPU\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sample, label = process_data('datasets/train50.h5')\n",
    "        test_samples, test_labels = process_data('datasets/test.h5')\n",
    "\n",
    "        graph_cost = []\n",
    "        graph_epoch = []\n",
    "        total_size = (sample.shape)[0]\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            cost_ = 0\n",
    "            i = 0\n",
    "\n",
    "            temp_sample = np.copy(sample)\n",
    "            temp_label = np.copy(label)\n",
    "\n",
    "            np.random.seed(epoch%1000)\n",
    "            np.random.shuffle(temp_sample)\n",
    "            np.random.seed(epoch%1000)\n",
    "            np.random.shuffle(temp_label)\n",
    "\n",
    "            #Minibatches\n",
    "            while i < total_size:\n",
    "                if i + batch_size < test_samples.shape[0]:\n",
    "                    batch_sample = temp_sample[i:i+batch_size]\n",
    "                    batch_label = temp_label[i:i+batch_size]\n",
    "                else:\n",
    "                    batch_sample = temp_sample[i:]\n",
    "                    batch_label = temp_label[i:]\n",
    "\n",
    "                _, c = sess.run([optimizer, cost], feed_dict = {x: batch_sample, y: batch_label})\n",
    "                i += batch_size\n",
    "                cost_ += c/(total_size/batch_size)\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                graph_epoch.append(epoch)\n",
    "                graph_cost.append(c)\n",
    "            \n",
    "            if epoch % 50 == 0:\n",
    "                print(str(epoch + 50) + \" out of \" + str(epochs) + \" completed. Loss: \" + str(c))\n",
    "\n",
    "\n",
    "        print(\"Relative Error for s2z on training set: \" +  str(s2z.eval({x: sample, y: label})) + \"%\")\n",
    "        print(\"Relative Error for s2z on test set: \" +  str(s2z.eval({x: test_samples, y: test_labels})) + \"%\")\n",
    "        \n",
    "        correct = (re_s2z < threshold)                          #see if the difference is less than the threshold\n",
    "        correct = tf.cast(correct, tf.float32)                  #convert boolean tensor to float32\n",
    "        accuracy = tf.reduce_mean(correct, axis=None) * 100     #convert to a percentage\n",
    "\n",
    "        print(\"Training set accuracy (less than \" + str(threshold) + \"% relative error): \" + str(accuracy.eval({x: sample, y: label})) + \"%\")\n",
    "        print(\"Test set accuracy (less than \" + str(threshold) + \"% relative error): \" + str(accuracy.eval({x: test_samples, y: test_labels})) + \"%\")\n",
    "        \n",
    "        plt.plot(graph_epoch, graph_cost)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test various hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################\n",
      "Learning rate: 0.0001 Batch size: 5\n",
      "######################################\n",
      "\n",
      "50 out of 200 completed. Loss: 0.0950932\n",
      "100 out of 200 completed. Loss: 9.21791e-06\n",
      "150 out of 200 completed. Loss: 1.5451e-07\n",
      "200 out of 200 completed. Loss: 1.2641e-07\n",
      "Relative Error for s2z on training set: 0.794643%\n",
      "Relative Error for s2z on test set: 3.31437%\n",
      "Training set accuracy (less than 5% relative error): 100.0%\n",
      "Test set accuracy (less than 5% relative error): 85.7143%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3eefe91122d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrs = [.0001]\n",
    "sizes = [5]\n",
    "\n",
    "for lr in lrs: \n",
    "    for size in sizes:\n",
    "        train(lr = lr, batch_size = size, threshold = 5, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
