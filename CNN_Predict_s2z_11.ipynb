{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Architecture for Predicting s2z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "import random\n",
    "import h5py as h5\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 6000, 1, 64)\n",
      "(?, 1200, 1, 128)\n",
      "(?, 240, 1, 256)\n",
      "(?, 48, 1, 256)\n",
      "(?, 12, 1, 256)\n"
     ]
    }
   ],
   "source": [
    "#Placeholders\n",
    "x = tf.placeholder(tf.float32, shape = [None, 30000])\n",
    "y = tf.placeholder(tf.float32, shape = [None, 3])\n",
    "\n",
    "#Reshape input\n",
    "inp = tf.reshape(x, [-1, 30000, 1, 1])\n",
    "\n",
    "#Convolutional layer 1,2\n",
    "w_conv1 = weight('w_conv1', [80, 1, 1, 64])\n",
    "b_conv1 = bias('b_conv1', [64])\n",
    "conv1 = tf.nn.relu(conv(inp, w_conv1) + b_conv1)\n",
    "\n",
    "w_conv2 = weight('w_conv2', [20, 1, 64, 64])\n",
    "b_conv2 = bias('b_conv2', [64])\n",
    "conv2 = tf.nn.relu(conv(conv1, w_conv2) + b_conv2)\n",
    "\n",
    "#Max pool 1\n",
    "conv2 = maxPool(conv2, 5)\n",
    "print(conv2.shape)\n",
    "\n",
    "#Convolutional layer 3,4\n",
    "w_conv3 = weight('w_conv3', [5, 1, 64, 128])\n",
    "b_conv3 = bias('b_conv3', [128])\n",
    "conv3 = tf.nn.relu(conv(conv2, w_conv3) + b_conv3)\n",
    "\n",
    "w_conv4 = weight('w_conv4', [5, 1, 128, 128])\n",
    "b_conv4 = bias('b_conv4', [128])\n",
    "conv4 = tf.nn.relu(conv(conv3, w_conv4) + b_conv4)\n",
    "\n",
    "#Max pool 2\n",
    "conv4 = maxPool(conv4, 5)\n",
    "print(conv4.shape)\n",
    "\n",
    "#Convolutional layer 5\n",
    "w_conv5 = weight('w_conv5', [5, 1, 128, 256])\n",
    "b_conv5 = bias('b_conv5', [256])\n",
    "conv5 = tf.nn.relu(conv(conv4, w_conv5) + b_conv5)\n",
    "\n",
    "#Convolutional layer 6\n",
    "w_conv6 = weight('w_conv6', [5, 1, 256, 256])\n",
    "b_conv6 = bias('b_conv6', [256])\n",
    "conv6 = tf.nn.relu(conv(conv5, w_conv6) + b_conv6)\n",
    "\n",
    "#Max pool 3\n",
    "conv6 = maxPool(conv6, 5)\n",
    "print(conv6.shape)\n",
    "\n",
    "#Convolutional layer 7\n",
    "w_conv7 = weight('w_conv7', [5, 1, 256, 256])\n",
    "b_conv7 = bias('b_conv7', [256])\n",
    "conv7 = tf.nn.relu(conv(conv6, w_conv7) + b_conv7)\n",
    "\n",
    "#Convolutional layer 8\n",
    "w_conv8 = weight('w_conv8', [5, 1, 256, 256])\n",
    "b_conv8 = bias('b_conv8', [256])\n",
    "conv8 = tf.nn.relu(conv(conv7, w_conv8) + b_conv8)\n",
    "\n",
    "#Max pool 4\n",
    "conv8 = maxPool(conv8, 5)\n",
    "print(conv8.shape)\n",
    "\n",
    "#Convolution layer 9\n",
    "w_conv9 = weight('w_conv9', [5, 1, 256, 256])\n",
    "b_conv9 = bias('b_conv9', [256])\n",
    "conv9 = tf.nn.relu(conv(conv8, w_conv9) + b_conv9)\n",
    "\n",
    "#Max pool 5\n",
    "conv9 = maxPool(conv9, 4)\n",
    "print(conv9.shape)\n",
    "\n",
    "#Flatten\n",
    "flat = tf.reshape(conv9, [-1, 12 * 256])\n",
    "\n",
    "#Fully connected layer\n",
    "w_fc = weight('w_fc', [12 * 256, 20])\n",
    "b_fc = bias('b_fc', [20])\n",
    "fc = tf.nn.relu(tf.matmul(flat, w_fc) + b_fc)\n",
    "#fc = tf.nn.dropout(fc, .9)\n",
    "\n",
    "\n",
    "#Output layer\n",
    "w_fc1 = weight('w_fc1', [20, 3])\n",
    "b_fc1 = bias('b_fc1', [3])\n",
    "prediction = (tf.matmul(fc, w_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lr, batch_size, threshold, epochs):\n",
    "    \n",
    "    print(\"\\n######################################\")\n",
    "    print(\"Learning rate: \" + str(lr) + \" Batch size: \" + str(batch_size))\n",
    "    print(\"######################################\\n\")\n",
    "\n",
    "    cost = (tf.losses.mean_squared_error(prediction, y))\n",
    "\n",
    "    re_q = tf.divide(tf.abs(tf.subtract(prediction[:,0], y[:,0])), y[:,0]) * 100  #Relative error\n",
    "    re_s1z = tf.divide(tf.abs(tf.subtract(prediction[:,1], y[:,1])), y[:,1]) * 100  #Relative error\n",
    "    re_s2z = tf.divide(tf.abs(tf.subtract(prediction[:,2], y[:,2])), (y[:,2])) * 100  #Relative error\n",
    "\n",
    "    q = tf.reduce_mean(re_q)\n",
    "    s1z = tf.reduce_mean(re_s1z)\n",
    "    s2z = tf.reduce_mean(re_s2z)\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(lr).minimize(cost)\n",
    "\n",
    "    # config = tf.ConfigProto(device_count = {'GPU': 0}) #Use CPU instead of GPU\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sample, label = process_data('trains1z.h5')\n",
    "        test_samples, test_labels = process_data('tests1z.h5')\n",
    "\n",
    "        graph_cost = []\n",
    "        graph_epoch = []\n",
    "        total_size = (sample.shape)[0]\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            cost_ = 0\n",
    "            i = 0\n",
    "\n",
    "            temp_sample = np.copy(sample)\n",
    "            temp_label = np.copy(label)\n",
    "\n",
    "            np.random.seed(epoch%1000)\n",
    "            np.random.shuffle(temp_sample)\n",
    "            np.random.seed(epoch%1000)\n",
    "            np.random.shuffle(temp_label)\n",
    "\n",
    "            #Minibatches\n",
    "            while i < total_size:\n",
    "                if i + batch_size < test_samples.shape[0]:\n",
    "                    batch_sample = temp_sample[i:i+batch_size]\n",
    "                    batch_label = temp_label[i:i+batch_size]\n",
    "                else:\n",
    "                    batch_sample = temp_sample[i:]\n",
    "                    batch_label = temp_label[i:]\n",
    "\n",
    "                _, c = sess.run([optimizer, cost], feed_dict = {x: batch_sample, y: batch_label})\n",
    "                i += batch_size\n",
    "                cost_ += c/(total_size/batch_size)\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                graph_epoch.append(epoch)\n",
    "                graph_cost.append(c)\n",
    "            \n",
    "            if epoch % 50 == 0:\n",
    "                print(str(epoch + 50) + \" out of \" + str(epochs) + \" completed. Loss: \" + str(c))\n",
    "\n",
    "\n",
    "        print(\"Relative Error for s2z on training set: \" +  str(s2z.eval({x: sample, y: label})) + \"%\")\n",
    "        print(\"Relative Error for s2z on test set: \" +  str(s2z.eval({x: test_samples, y: test_labels})) + \"%\")\n",
    "        \n",
    "        correct = (re_s2z < threshold)                          #see if the difference is less than the threshold\n",
    "        correct = tf.cast(correct, tf.float32)                  #convert boolean tensor to float32\n",
    "        accuracy = tf.reduce_mean(correct, axis=None) * 100     #convert to a percentage\n",
    "\n",
    "        print(\"Training set accuracy (less than \" + str(threshold) + \"% relative error): \" + str(accuracy.eval({x: sample, y: label})) + \"%\")\n",
    "        print(\"Test set accuracy (less than \" + str(threshold) + \"% relative error): \" + str(accuracy.eval({x: test_samples, y: test_labels})) + \"%\")\n",
    "        \n",
    "        plt.plot(graph_epoch, graph_cost)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test various hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################\n",
      "Learning rate: 0.0001 Batch size: 5\n",
      "######################################\n",
      "\n",
      "50 out of 1000 completed. Loss: 0.248092\n",
      "100 out of 1000 completed. Loss: 0.00135165\n",
      "150 out of 1000 completed. Loss: 1.62494e-06\n",
      "200 out of 1000 completed. Loss: 3.38848e-07\n",
      "250 out of 1000 completed. Loss: 6.58471e-09\n",
      "300 out of 1000 completed. Loss: 4.81405e-08\n",
      "350 out of 1000 completed. Loss: 3.09833e-07\n",
      "400 out of 1000 completed. Loss: 1.36742e-05\n",
      "450 out of 1000 completed. Loss: 1.20884e-05\n",
      "500 out of 1000 completed. Loss: 4.16514e-05\n",
      "550 out of 1000 completed. Loss: 7.49236e-06\n",
      "600 out of 1000 completed. Loss: 5.60255e-05\n",
      "650 out of 1000 completed. Loss: 2.71718e-06\n",
      "700 out of 1000 completed. Loss: 1.24356e-05\n",
      "750 out of 1000 completed. Loss: 4.65235e-05\n",
      "800 out of 1000 completed. Loss: 1.48151e-05\n",
      "850 out of 1000 completed. Loss: 8.69746e-05\n",
      "900 out of 1000 completed. Loss: 1.54314e-05\n",
      "950 out of 1000 completed. Loss: 6.11355e-07\n",
      "1000 out of 1000 completed. Loss: 3.25212e-05\n",
      "Relative Error for s2z on training set: 1.64962%\n",
      "Relative Error for s2z on test set: 1.74808%\n",
      "Training set accuracy (less than 5% relative error): 100.0%\n",
      "Test set accuracy (less than 5% relative error): 100.0%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3fff5757fd10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrs = [.0001]\n",
    "sizes = [5]\n",
    "\n",
    "for lr in lrs: \n",
    "    for size in sizes:\n",
    "        train(lr = lr, batch_size = size, threshold = 5, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
